{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import PyPDF2\n",
    "import docx2txt\n",
    "import sys\n",
    "from nltk.tokenize.punkt import PunktSentenceTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are going to show an example of how the method is working\n",
    "# first let's take the document as an input\n",
    "def readDoc(name):\n",
    "\n",
    "    # now read the type of document\n",
    "    if name.lower().endswith('.txt'):\n",
    "        choice = 1\n",
    "    elif name.lower().endswith('.pdf'):\n",
    "        choice = 2\n",
    "    else:\n",
    "        choice = 3\n",
    "        # print(name)\n",
    "    # print(choice)\n",
    "    # Case 1: if it is a .txt file\n",
    "        \n",
    "    if choice == 1:\n",
    "        f = open(name, 'r', encoding=\"utf8\")\n",
    "        document = f.read()\n",
    "        f.close()\n",
    "            \n",
    "    # Case 2: if it is a .pdf file\n",
    "    elif choice == 2:\n",
    "        pdfFileObj = open(name, 'rb', encoding=\"utf8\")\n",
    "        pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
    "        pageObj = pdfReader.getPage(0)\n",
    "        document = pageObj.extractText()\n",
    "        pdfFileObj.close()\n",
    "    \n",
    "    # Case 3: none of the format\n",
    "    else:\n",
    "        print('Failed to load a valid file')\n",
    "        print('Returning an empty string')\n",
    "        document = ''\n",
    "    \n",
    "    # print(type(document))\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(document):\n",
    "    # We are tokenizing using the PunktSentenceTokenizer\n",
    "    # we call an instance of this class as sentence_tokenizer\n",
    "    doc_tokenizer = PunktSentenceTokenizer()\n",
    "    \n",
    "    # tokenize() method: takes our document as input and returns a list of all the sentences in the document\n",
    "    \n",
    "    # sentences is a list containing each sentence of the document as an element\n",
    "    sentences_list = doc_tokenizer.tokenize(document)\n",
    "    return sentences_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = readDoc(\"berita1.txt\")\n",
    "sentences_list = tokenize(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "cv_matrix = cv.fit_transform(sentences_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_matrix = TfidfTransformer().fit_transform(cv_matrix)\n",
    "res_graph = normal_matrix * normal_matrix.T\n",
    "# plt.spy(res_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_graph = nx.from_scipy_sparse_array(res_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = nx.pagerank(nx_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_array = sorted(((ranks[i], s) for i, s in enumerate(sentences_list)), reverse=True)\n",
    "sentence_array = np.asarray(sentence_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_max = float(sentence_array[0][0])\n",
    "rank_min = float(sentence_array[len(sentence_array) - 1][0])\n",
    "\n",
    "temp_array = []\n",
    "\n",
    "# if all sentences have equal ranks, means they are all the same\n",
    "# taking any sentence will give the summary, say the first sentence\n",
    "flag = 0\n",
    "if rank_max - rank_min == 0:\n",
    "    temp_array.append(0)\n",
    "    flag = 1\n",
    "\n",
    "# If the sentence has different ranks\n",
    "if flag != 1:\n",
    "    for i in range(0, len(sentence_array)):\n",
    "        temp_array.append((float(sentence_array[i][0]) - rank_min) / (rank_max - rank_min))\n",
    "threshold = (sum(temp_array) / len(temp_array)) + 0.2\n",
    "sentence_list = []\n",
    "if len(temp_array) > 1:\n",
    "    for i in range(0, len(temp_array)):\n",
    "        if temp_array[i] > threshold:\n",
    "                sentence_list.append(sentence_array[i][1])\n",
    "else:\n",
    "    sentence_list.append(sentence_array[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kronologi OTT Wali Kota Yana Mulyana Dkk Terkait Suap Rp 924,6 Juta untuk Bandung Smart City Modus THR sebagai gratifikasi atau suap terhadap pejabat negara juga terjadi dalam pelaksanaan OTT beberapa waktu lalu.\n",
      "KPK Amankan Uang Asing hingga Sepatu Louis Vuitton Saat OTT Wali Kota Bandung Yana MulyanaYana diduga menerima suap dalam proyek pengadaan closed circuit television (CCTV) dan internet service provider (ISP) untuk layanan digital Bandung Smart City di Pemerintah Kota Bandung, Jawa Barat tahun anggaran 2022-2023.\n",
      "Terkini, modus THR terungkap dalam operasi tangkap tangan (OTT) terhadap Wali Kota Bandung Yana Mulyana pada Jumat (15/4/2023).\n"
     ]
    }
   ],
   "source": [
    "# summary = \" \".join(str(x) for x in sentence_list)\n",
    "# print(summary)\n",
    "\n",
    "for i in sentence_list:\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
